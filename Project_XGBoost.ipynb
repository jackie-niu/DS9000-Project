{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed12c57d",
   "metadata": {},
   "source": [
    "# Insurance Fraud Detection â€“ DS3000/DS9000 Project\n",
    "**Goal:** Exploring Machine Learning Techniques for Insurance Fraud Detection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65678ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b771e8",
   "metadata": {},
   "source": [
    "## Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce415497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "df = pd.read_excel('Worksheet in Case Study question 2.xlsx', sheet_name=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367c5ec9",
   "metadata": {},
   "source": [
    "## Cleaning missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ce9f96",
   "metadata": {},
   "source": [
    "It is observed that the missing values are given by ? instead of null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11658da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace ? with NaN\n",
    "df=df.replace('?',np.nan)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925c6d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de00c7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill null values with 'Unknown' since having a missing value carries information in this context\n",
    "df['collision_type'] = df['collision_type'].fillna('Unknown')\n",
    "df['property_damage'] = df['property_damage'].fillna('Unknown')\n",
    "df['police_report_available'] = df['police_report_available'].fillna('Unknown')\n",
    "df['authorities_contacted'] = df['authorities_contacted'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2236eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4695ffed",
   "metadata": {},
   "source": [
    "## Checking class balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021c72fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fraud_reported'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498189ed",
   "metadata": {},
   "source": [
    "The split is roughly 75-25 in favor of no fraud."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a88b14",
   "metadata": {},
   "source": [
    "## Drop identifiers and free-text location fields (high-cardinality / leak risk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5719d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [\n",
    "        \"policy_number\", \"policy_bind_date\", \"incident_date\",\n",
    "        \"incident_location\", \"insured_zip\"\n",
    "    ]\n",
    "\n",
    "for c in drop_cols:\n",
    "    df = df.drop(columns=c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee657461",
   "metadata": {},
   "source": [
    "## Check data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2180c5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ef83d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ffac8e",
   "metadata": {},
   "source": [
    "## Categorical Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4707c011",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a368f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# One-hot encode all categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "df = pd.get_dummies(df, columns=categorical_cols, drop_first=True) \n",
    "\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dd1686",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d4a6f1",
   "metadata": {},
   "source": [
    "## Look at distribution and correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df74bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "df.hist(figsize=(24, 20))\n",
    "\n",
    "for col in df:\n",
    "    sns.histplot(df[col], kde=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49c7630",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr(numeric_only=True)\n",
    "sns.heatmap(corr, cmap='coolwarm', annot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d5410e",
   "metadata": {},
   "source": [
    "## Split and Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "51bae769",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "y = df['fraud_reported_Y']\n",
    "X = df.drop(columns=['fraud_reported_Y'])\n",
    "\n",
    "numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X[numeric_cols] = scaler.fit_transform(X[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc0ef1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f08d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2df116f",
   "metadata": {},
   "source": [
    "### Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfb5504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a train/test split but with validation, since we will be tuning hyperparameters\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.3,        # 30% for temp (val + test)\n",
    "    random_state=42,\n",
    "    stratify=y            # maintain class balance\n",
    ")\n",
    "\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    test_size=0.5,\n",
    "    random_state=42,\n",
    "    stratify=y_temp\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadbe61f",
   "metadata": {},
   "source": [
    "## Check class balance of sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec38da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_survival_rate = y_train.mean() * 100\n",
    "val_survival_rate = y_val.mean() * 100\n",
    "test_survival_rate = y_test.mean() * 100\n",
    "\n",
    "print(f\"Train set survival rate: {train_survival_rate:.2f}%\")\n",
    "print(f\"Validation set survival rate:  {val_survival_rate:.2f}%\")\n",
    "print(f\"Test set survival rate:  {test_survival_rate:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f34c4f2",
   "metadata": {},
   "source": [
    "## Build XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fd46d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],        # number of boosting rounds\n",
    "    'max_depth': [3, 4, 5, 6],              # depth of each tree\n",
    "    'learning_rate': [0.01, 0.05, 0.1],     # step size shrinkage\n",
    "    'subsample': [0.8, 1.0],                # fraction of samples used per tree\n",
    "    'colsample_bytree': [0.8, 1.0],         # fraction of features used per tree\n",
    "    'gamma': [0, 0.5, 1],                   # minimum loss reduction to make a split\n",
    "    'reg_lambda': [1, 5, 10]                # L2 regularization strength\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91dd8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(random_state = 42)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=xgb,\n",
    "    scoring='accuracy',\n",
    "    cv=3,\n",
    "    param_grid=param_grid,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1915fa66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8328564616118265\n",
      "{'colsample_bytree': 1.0, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'reg_lambda': 1, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
