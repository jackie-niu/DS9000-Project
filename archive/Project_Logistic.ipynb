{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic-Net Logistic Regression —-(Fraud Detection)\n",
    "\n",
    "**Goal**: Exploring Machine Learning Techniques for Insurance Fraud Detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adc7e76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Imports & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory: /Users/echo/Desktop/9000_finalProject/outputs_elasticnet_step\n"
     ]
    }
   ],
   "source": [
    "import os, json, warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_predict\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, average_precision_score, classification_report,\n",
    "    precision_recall_curve, roc_curve, confusion_matrix, ConfusionMatrixDisplay\n",
    ")\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DATA_PATH   = 'Worksheet in Case Study question 2.xlsx'  # adjust if needed\n",
    "TARGET      = 'fraud_reported'\n",
    "SEED        = 42\n",
    "OUT_DIR     = Path('outputs_elasticnet_step')\n",
    "MODEL_NAME  = 'logreg_elasticnet'\n",
    "MODEL_FILE  = OUT_DIR / f'{MODEL_NAME}_best.joblib'\n",
    "METRICS_LOG = Path('metrics.jsonl')\n",
    "\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print('Output directory:', OUT_DIR.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Load the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>months_as_customer</th>\n",
       "      <th>age</th>\n",
       "      <th>policy_number</th>\n",
       "      <th>policy_bind_date</th>\n",
       "      <th>policy_state</th>\n",
       "      <th>policy_csl</th>\n",
       "      <th>policy_deductable</th>\n",
       "      <th>policy_annual_premium</th>\n",
       "      <th>umbrella_limit</th>\n",
       "      <th>insured_zip</th>\n",
       "      <th>...</th>\n",
       "      <th>witnesses</th>\n",
       "      <th>police_report_available</th>\n",
       "      <th>total_claim_amount</th>\n",
       "      <th>injury_claim</th>\n",
       "      <th>property_claim</th>\n",
       "      <th>vehicle_claim</th>\n",
       "      <th>auto_make</th>\n",
       "      <th>auto_model</th>\n",
       "      <th>auto_year</th>\n",
       "      <th>fraud_reported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>328</td>\n",
       "      <td>48</td>\n",
       "      <td>521585</td>\n",
       "      <td>2014-10-17</td>\n",
       "      <td>OH</td>\n",
       "      <td>250/500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1406.91</td>\n",
       "      <td>0</td>\n",
       "      <td>466132</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>YES</td>\n",
       "      <td>71610</td>\n",
       "      <td>6510</td>\n",
       "      <td>13020</td>\n",
       "      <td>52080</td>\n",
       "      <td>Saab</td>\n",
       "      <td>92x</td>\n",
       "      <td>2004</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>228</td>\n",
       "      <td>42</td>\n",
       "      <td>342868</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>IN</td>\n",
       "      <td>250/500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1197.22</td>\n",
       "      <td>5000000</td>\n",
       "      <td>468176</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>?</td>\n",
       "      <td>5070</td>\n",
       "      <td>780</td>\n",
       "      <td>780</td>\n",
       "      <td>3510</td>\n",
       "      <td>Mercedes</td>\n",
       "      <td>E400</td>\n",
       "      <td>2007</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>134</td>\n",
       "      <td>29</td>\n",
       "      <td>687698</td>\n",
       "      <td>2000-09-06</td>\n",
       "      <td>OH</td>\n",
       "      <td>100/300</td>\n",
       "      <td>2000</td>\n",
       "      <td>1413.14</td>\n",
       "      <td>5000000</td>\n",
       "      <td>430632</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>NO</td>\n",
       "      <td>34650</td>\n",
       "      <td>7700</td>\n",
       "      <td>3850</td>\n",
       "      <td>23100</td>\n",
       "      <td>Dodge</td>\n",
       "      <td>RAM</td>\n",
       "      <td>2007</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>256</td>\n",
       "      <td>41</td>\n",
       "      <td>227811</td>\n",
       "      <td>1990-05-25</td>\n",
       "      <td>IL</td>\n",
       "      <td>250/500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1415.74</td>\n",
       "      <td>6000000</td>\n",
       "      <td>608117</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>NO</td>\n",
       "      <td>63400</td>\n",
       "      <td>6340</td>\n",
       "      <td>6340</td>\n",
       "      <td>50720</td>\n",
       "      <td>Chevrolet</td>\n",
       "      <td>Tahoe</td>\n",
       "      <td>2014</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>228</td>\n",
       "      <td>44</td>\n",
       "      <td>367455</td>\n",
       "      <td>2014-06-06</td>\n",
       "      <td>IL</td>\n",
       "      <td>500/1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1583.91</td>\n",
       "      <td>6000000</td>\n",
       "      <td>610706</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NO</td>\n",
       "      <td>6500</td>\n",
       "      <td>1300</td>\n",
       "      <td>650</td>\n",
       "      <td>4550</td>\n",
       "      <td>Accura</td>\n",
       "      <td>RSX</td>\n",
       "      <td>2009</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   months_as_customer  age  policy_number policy_bind_date policy_state  \\\n",
       "0                 328   48         521585       2014-10-17           OH   \n",
       "1                 228   42         342868       2006-06-27           IN   \n",
       "2                 134   29         687698       2000-09-06           OH   \n",
       "3                 256   41         227811       1990-05-25           IL   \n",
       "4                 228   44         367455       2014-06-06           IL   \n",
       "\n",
       "  policy_csl  policy_deductable  policy_annual_premium  umbrella_limit  \\\n",
       "0    250/500               1000                1406.91               0   \n",
       "1    250/500               2000                1197.22         5000000   \n",
       "2    100/300               2000                1413.14         5000000   \n",
       "3    250/500               2000                1415.74         6000000   \n",
       "4   500/1000               1000                1583.91         6000000   \n",
       "\n",
       "   insured_zip  ... witnesses police_report_available total_claim_amount  \\\n",
       "0       466132  ...         2                     YES              71610   \n",
       "1       468176  ...         0                       ?               5070   \n",
       "2       430632  ...         3                      NO              34650   \n",
       "3       608117  ...         2                      NO              63400   \n",
       "4       610706  ...         1                      NO               6500   \n",
       "\n",
       "  injury_claim property_claim  vehicle_claim  auto_make auto_model auto_year  \\\n",
       "0         6510          13020          52080       Saab        92x      2004   \n",
       "1          780            780           3510   Mercedes       E400      2007   \n",
       "2         7700           3850          23100      Dodge        RAM      2007   \n",
       "3         6340           6340          50720  Chevrolet      Tahoe      2014   \n",
       "4         1300            650           4550     Accura        RSX      2009   \n",
       "\n",
       "  fraud_reported  \n",
       "0              Y  \n",
       "1              Y  \n",
       "2              N  \n",
       "3              Y  \n",
       "4              N  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the Excel. Ensure the file is placed next to this notebook or update DATA_PATH.\n",
    "df = pd.read_excel(DATA_PATH, sheet_name=0)\n",
    "assert TARGET in df.columns, f\"Target column '{TARGET}' not found.\"\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19894b50",
   "metadata": {},
   "source": [
    "## 2.5) Clean the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "096b64d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "property_damage            360\n",
       "police_report_available    343\n",
       "collision_type             178\n",
       "authorities_contacted       91\n",
       "auto_model                   0\n",
       "auto_make                    0\n",
       "vehicle_claim                0\n",
       "property_claim               0\n",
       "injury_claim                 0\n",
       "total_claim_amount           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace '?' with NaN\n",
    "df = df.replace('?', np.nan)\n",
    "# Check missing values\n",
    "df.isna().sum().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6591fffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['collision_type', 'property_damage', 'police_report_available', 'authorities_contacted']\n",
    "for c in cols:\n",
    "    if c in df.columns:\n",
    "        df[c] = df[c].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55e307b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "months_as_customer             0\n",
       "witnesses                      0\n",
       "incident_state                 0\n",
       "incident_city                  0\n",
       "incident_location              0\n",
       "incident_hour_of_the_day       0\n",
       "number_of_vehicles_involved    0\n",
       "property_damage                0\n",
       "bodily_injuries                0\n",
       "police_report_available        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Checking class balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fraud_reported\n",
       "N    0.753\n",
       "Y    0.247\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The split is roughly 75%-25% in favor of N.\n",
      "Positive rate (Y): 24.7%\n"
     ]
    }
   ],
   "source": [
    "# Normalize=True shows proportions (Y vs N)\n",
    "TARGET = \"fraud_reported\"   \n",
    "POS    = \"Y\"                # positive label (fraud)\n",
    "\n",
    "s = df[TARGET].value_counts(normalize=True).rename(\"proportion\")\n",
    "display(s)                  \n",
    "\n",
    "major = s.idxmax()\n",
    "print(f\"The split is roughly {s[major]:.0%}-{1-s[major]:.0%} in favor of {major}.\")\n",
    "print(f\"Positive rate ({POS}): {s.get(POS, 0):.1%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Drop identifiers and free-text location fields (high-cardinality / leak risk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust this list based on schema. We avoid using near-unique IDs and raw addresses.\n",
    "ID_COLS = ['policy_number', 'incident_location', 'insured_zip']\n",
    "df = df.drop(columns=[c for c in ID_COLS if c in df.columns])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Derive interpretable features from dates/times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>policy_tenure_days</th>\n",
       "      <th>incident_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3130</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5282</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8996</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>256</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   policy_tenure_days  incident_hour\n",
       "0                 100              5\n",
       "1                3130              8\n",
       "2                5282              7\n",
       "3                8996              5\n",
       "4                 256             20"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Parse dates\n",
    "for col in ['policy_bind_date', 'incident_date']:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "\n",
    "# 2) Tenure in days: incident_date - policy_bind_date\n",
    "if {'policy_bind_date','incident_date'}.issubset(df.columns):\n",
    "    df['policy_tenure_days'] = (df['incident_date'] - df['policy_bind_date']).dt.days\n",
    "\n",
    "# 3) Hour of day: dataset already has 'incident_hour_of_the_day' (0–23)\n",
    "if 'incident_hour_of_the_day' in df.columns:\n",
    "    df['incident_hour'] = pd.to_numeric(df['incident_hour_of_the_day'], errors='coerce')\n",
    "else:\n",
    "    df['incident_hour'] = np.nan  # fallback if the column is missing\n",
    "\n",
    "# 4) After creating useful signals, drop the raw date/time columns to avoid high cardinality/redundancy\n",
    "to_drop_after_fe = [c for c in ['policy_bind_date','incident_date','incident_hour_of_the_day'] if c in df.columns]\n",
    "df = df.drop(columns=to_drop_after_fe)\n",
    "\n",
    "# 5) Quick preview\n",
    "df[['policy_tenure_days','incident_hour']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Check data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "months_as_customer               int64\n",
       "age                              int64\n",
       "policy_state                    object\n",
       "policy_csl                      object\n",
       "policy_deductable                int64\n",
       "policy_annual_premium          float64\n",
       "umbrella_limit                   int64\n",
       "insured_sex                     object\n",
       "insured_education_level         object\n",
       "insured_occupation              object\n",
       "insured_hobbies                 object\n",
       "insured_relationship            object\n",
       "capital-gains                    int64\n",
       "capital-loss                     int64\n",
       "incident_type                   object\n",
       "collision_type                  object\n",
       "incident_severity               object\n",
       "authorities_contacted           object\n",
       "incident_state                  object\n",
       "incident_city                   object\n",
       "number_of_vehicles_involved      int64\n",
       "property_damage                 object\n",
       "bodily_injuries                  int64\n",
       "witnesses                        int64\n",
       "police_report_available         object\n",
       "total_claim_amount               int64\n",
       "injury_claim                     int64\n",
       "property_claim                   int64\n",
       "vehicle_claim                    int64\n",
       "auto_make                       object\n",
       "auto_model                      object\n",
       "auto_year                        int64\n",
       "fraud_reported                  object\n",
       "policy_tenure_days               int64\n",
       "incident_hour                    int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Prepare `X` and `y`\n",
    "Create the **feature matrix `X`** and the **label vector `y`**.  \n",
    "- Encode the target `fraud_reported` as **1 for 'Y'** and **0 for 'N'** so scikit-learn can train.  \n",
    "- **Drop rows with missing target** to avoid training on unlabeled data.  \n",
    "- `X.shape, y.mean()` prints the dataset size and the **positive rate** (baseline fraud rate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 34), 0.247)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map target to {0,1}; drop rows with missing target\n",
    "df = df.dropna(subset=[TARGET]).copy()\n",
    "y = df[TARGET].astype(str).str.upper().map({'Y':1,'N':0}).astype(int)\n",
    "X = df.drop(columns=[TARGET])\n",
    "X.shape, y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Train/Validation/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "TEST_SIZE = 0.20\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=SEED, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) Preprocess: fit on training set (numeric = median+scale, categorical = mode+one-hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric: 17 | Categorical: 17\n"
     ]
    }
   ],
   "source": [
    "# 1) Identify columns from X_train (single Train/Test split)\n",
    "num_cols = X_train.select_dtypes(include=['number','float','int','bool']).columns.tolist()\n",
    "cat_cols = X_train.select_dtypes(include=['object','category']).columns.tolist()\n",
    "\n",
    "# 2) Ensure these are treated as categorical even if stored as numbers\n",
    "for c in ['insured_zip', 'policy_state', 'policy_csl']:\n",
    "    if c in X_train.columns and c in num_cols:\n",
    "        num_cols.remove(c)\n",
    "        cat_cols.append(c)\n",
    "\n",
    "# 3) Simple pipelines\n",
    "numeric_pipe = Pipeline([\n",
    "    ('imp', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipe = Pipeline([\n",
    "    ('imp', SimpleImputer(strategy='most_frequent')),   \n",
    "    ('oh', OneHotEncoder(handle_unknown='ignore', sparse=True))\n",
    "])\n",
    "\n",
    "# 4) Column-wise transformer\n",
    "pre = ColumnTransformer([\n",
    "    ('num', numeric_pipe, num_cols),\n",
    "    ('cat', categorical_pipe, cat_cols)\n",
    "])\n",
    "\n",
    "print(f\"Numeric: {len(num_cols)} | Categorical: {len(cat_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10) Model (single split): Elastic-Net Logistic Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db10233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure categorical columns are strings (avoid mixed int/str for OneHotEncoder)\n",
    "cat_cols_fix = X_train.select_dtypes(include=['object','category']).columns.tolist()\n",
    "cat_cols_fix = sorted(set(cat_cols_fix ))\n",
    "\n",
    "\n",
    "X_train[cat_cols_fix] = X_train[cat_cols_fix].astype(str)\n",
    "X_test[cat_cols_fix]  = X_test[cat_cols_fix].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elastic-Net params -> C: 1.0, l1_ratio: 0.5\n",
      "Accuracy for Elastic-Net: 82.50%\n",
      "AUC for Elastic-Net: 0.83\n",
      "Precision for Elastic-Net: 62.96%\n",
      "Recall for Elastic-Net: 69.39%\n",
      "F1 Score for Elastic-Net: 66.02%\n",
      "Average Precision Score for Elastic-Net: 0.53\n"
     ]
    }
   ],
   "source": [
    "SEED = 42 \n",
    "\n",
    "clf = Pipeline([\n",
    "    ('prep', pre),\n",
    "    ('clf', LogisticRegression(\n",
    "        penalty='elasticnet', solver='saga',\n",
    "        l1_ratio=0.5, C=1.0, class_weight='balanced',\n",
    "        max_iter=4000, random_state=SEED\n",
    "    ))\n",
    "])\n",
    "\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "proba_test = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# metrics\n",
    "acc  = accuracy_score(y_test, y_pred)\n",
    "auc  = roc_auc_score(y_test, proba_test)                   # ROC-AUC\n",
    "prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "rec  = recall_score(y_test, y_pred, zero_division=0)\n",
    "f1   = f1_score(y_test, y_pred, zero_division=0)\n",
    "aps  = average_precision_score(y_test, proba_test)         # PR-AUC\n",
    "\n",
    "\n",
    "C_val        = clf.named_steps['clf'].C\n",
    "l1_ratio_val = clf.named_steps['clf'].l1_ratio\n",
    "print(f\"Elastic-Net params -> C: {C_val}, l1_ratio: {l1_ratio_val}\")\n",
    "print(f\"Accuracy for Elastic-Net: {acc:.2%}\")\n",
    "print(f\"AUC for Elastic-Net: {auc:.2f}\")\n",
    "print(f\"Precision for Elastic-Net: {prec:.2%}\")\n",
    "print(f\"Recall for Elastic-Net: {rec:.2%}\")\n",
    "print(f\"F1 Score for Elastic-Net: {f1:.2%}\")\n",
    "print(f\"Average Precision Score for Elastic-Net: {aps:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5953d8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Metrics appended to models/metrics.jsonl\n",
      "✔ Model saved to models/elasticnet_best.joblib\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, json, time, joblib\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "\n",
    "C_val = getattr(clf.named_steps['clf'], 'C', 1.0)\n",
    "l1_ratio_val = getattr(clf.named_steps['clf'], 'l1_ratio', 0.5)\n",
    "\n",
    "record = {\n",
    "    \"timestamp\": time.strftime(\"%Y-%m-%dT%H:%M:%S\"),\n",
    "    \"model\": \"ElasticNet\",\n",
    "    \"seed\": 42,\n",
    "    \"test_size\": 0.20,\n",
    "    \"params\": {\"penalty\":\"elasticnet\",\"C\": float(C_val), \"l1_ratio\": float(l1_ratio_val)},\n",
    "\n",
    "    \"pr_auc\": float(aps),     # = Average Precision (PR-AUC)\n",
    "    \"roc_auc\": float(auc),    # ROC-AUC\n",
    "    \n",
    "    \"test_metrics\": {\n",
    "        \"accuracy\": float(acc),\n",
    "        \"precision\": float(prec),\n",
    "        \"recall\": float(rec),\n",
    "        \"f1\": float(f1),\n",
    "        \"average_precision\": float(aps),\n",
    "        \"roc_auc\": float(auc)\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(\"models/metrics.jsonl\", \"a\", encoding=\"utf-8\") as f:\n",
    "    f.write(json.dumps(record) + \"\\n\")\n",
    "\n",
    "\n",
    "joblib.dump(clf, \"models/elasticnet_best.joblib\")\n",
    "\n",
    "print(\"✔ Metrics appended to models/metrics.jsonl\")\n",
    "print(\"✔ Model saved to models/elasticnet_best.joblib\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
