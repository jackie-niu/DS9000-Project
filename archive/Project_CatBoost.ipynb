{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed12c57d",
   "metadata": {},
   "source": [
    "# Insurance Fraud Detection â€“ DS3000/DS9000 Project\n",
    "**Goal:** Exploring Machine Learning Techniques for Insurance Fraud Detection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65678ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b771e8",
   "metadata": {},
   "source": [
    "## Import & Preprocess the dataset\n",
    "#### Please check detailed explaination in [other] files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce415497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "df = pd.read_excel('Worksheet in Case Study question 2.xlsx', sheet_name=0)\n",
    "df=df.replace('?',np.nan)\n",
    "\n",
    "# Fill null values with 'Unknown' since having a missing value carries information in this context\n",
    "df['collision_type'] = df['collision_type'].fillna('Unknown')\n",
    "df['property_damage'] = df['property_damage'].fillna('Unknown')\n",
    "df['police_report_available'] = df['police_report_available'].fillna('Unknown')\n",
    "df['authorities_contacted'] = df['authorities_contacted'].fillna('Unknown')\n",
    "\n",
    "## Checking class balance\n",
    "df['fraud_reported'].value_counts(normalize=True)\n",
    "drop_cols = [\n",
    "        \"policy_number\", \"policy_bind_date\", \"incident_date\",\n",
    "        \"incident_location\", \"insured_zip\"\n",
    "    ]\n",
    "\n",
    "for c in drop_cols:\n",
    "    df = df.drop(columns=c)\n",
    "\n",
    "## One-hot encode all categorical columns\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "#categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "#df = pd.get_dummies(df, columns=categorical_cols, drop_first=True) \n",
    "\n",
    "## Split and Scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "y = df['fraud_reported']\n",
    "X = df.drop(columns=['fraud_reported'])\n",
    "numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "scaler = StandardScaler()\n",
    "X[numeric_cols] = scaler.fit_transform(X[numeric_cols])\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,        \n",
    "    random_state=42,\n",
    "    stratify=y            # maintain class balance\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f34c4f2",
   "metadata": {},
   "source": [
    "## Build Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fd46d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "base = CatBoostClassifier(\n",
    "    loss_function=\"Logloss\",\n",
    "    eval_metric=\"AUC\",\n",
    "    verbose=False,\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "cat_features = [\n",
    "    i\n",
    "    for i, c in enumerate(X.columns)\n",
    "    if (X[c].dtype == \"object\" or str(X[c].dtype) == \"category\")\n",
    "]\n",
    "\n",
    "param_grid = {\n",
    "    \"depth\": [4, 6, 8],\n",
    "    \"learning_rate\": [0.03, 0.06, 0.1],\n",
    "    \"l2_leaf_reg\": [1, 3, 7],\n",
    "    \"iterations\": [300, 600],\n",
    "    \"bagging_temperature\": [0, 0.5, 1.0],\n",
    "    \"random_strength\": [1, 2]\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=base,\n",
    "    param_grid=param_grid, \n",
    "    scoring=\"roc_auc\",\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train, cat_features=cat_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05248ec",
   "metadata": {},
   "source": [
    "## Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c1d50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "from sklearn.metrics import accuracy_score\n",
    "best_model = grid.best_estimator_\n",
    "y_pred = grid.best_estimator_.predict(X_test)\n",
    "\n",
    "mapping = {\"Y\": 1, \"N\": 0, \"y\": 1, \"n\": 0}\n",
    "y_test = pd.Series(y_test).map(mapping).astype(int)\n",
    "y_pred = pd.Series(y_pred).map(mapping).astype(int)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faca4af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, average_precision_score, confusion_matrix\n",
    "acc_rf = accuracy_score(y_test, y_pred)\n",
    "auc_rf = roc_auc_score(y_test, y_pred)\n",
    "precision_rf = precision_score(y_test, y_pred, zero_division=0)\n",
    "recall_rf = recall_score(y_test, y_pred, zero_division=0)\n",
    "f1_score_rf = f1_score(y_test, y_pred, zero_division=0)\n",
    "average_precision_score_rf = average_precision_score(y_test, y_pred)\n",
    "y_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(f'Accuracy for CatBoost: {acc_rf:.2%}')\n",
    "print(f'AUC for CatBoost: {auc_rf:.2f}')\n",
    "print(f'Precision for CatBoost: {precision_rf:.2%}')\n",
    "print(f'Recall for CatBoost: {recall_rf:.2%}')\n",
    "print(f'F1 Score for CatBoost: {f1_score_rf:.2%}')\n",
    "print(f'Average Precision Score for CatBoost: {average_precision_score_rf:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406494d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import json\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "from typing import Any, Dict, Optional\n",
    "\n",
    "# Model I/O\n",
    "def save_model(model: Any, path: str) -> str:\n",
    "    p = Path(path)\n",
    "    p.parent.mkdir(parents=True, exist_ok=True)\n",
    "    joblib.dump(model, p)\n",
    "    return str(p)\n",
    "\n",
    "\n",
    "# Metrics storage\n",
    "def append_metrics_jsonl(record: Dict[str, Any], path: str = \"models/metrics.jsonl\") -> str:\n",
    "    p = Path(path)\n",
    "    p.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with p.open(\"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(record) + \"\\n\")\n",
    "    return str(p)\n",
    "\n",
    "\n",
    "def load_metrics_jsonl(path: str = \"models/metrics.jsonl\") -> list[Dict[str, Any]]:\n",
    "    p = Path(path)\n",
    "    if not p.exists():\n",
    "        return []\n",
    "    records = []\n",
    "    with p.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                records.append(json.loads(line))\n",
    "    return records\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "roc_auc = roc_auc_score(y_test, y_prob) if (y_prob is not None and y_test.nunique() == 2) else None\n",
    "ap = average_precision_score(y_test, y_prob) if (y_prob is not None and y_test.nunique() == 2) else None\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "metrics_record = {\n",
    "        \"timestamp\": datetime.utcnow().isoformat(),\n",
    "        \"model\": \"CatBoost\",\n",
    "        \"best_params\": grid.best_params_,\n",
    "        \"cv_best_accuracy\": float(grid.best_score_),\n",
    "        \"test_metrics\": {\n",
    "            \"accuracy\": float(acc),\n",
    "            \"precision\": float(prec),\n",
    "            \"recall\": float(rec),\n",
    "            \"f1\": float(f1),\n",
    "            \"roc_auc\": float(roc_auc) if roc_auc is not None else None,\n",
    "            \"average_precision\": float(ap) if ap is not None else None,\n",
    "            \"confusion_matrix\": cm.tolist(),\n",
    "        },\n",
    "    }\n",
    "save_model(best_model, \"models/nn.joblib\")\n",
    "append_metrics_jsonl(metrics_record, \"models/metrics.jsonl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
